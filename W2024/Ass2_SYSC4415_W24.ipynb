{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrgreen7/SYSC4906/blob/master/W2024/Ass2_SYSC4415_W24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to SYSC4415 Assignment 2\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "---\n",
        "**TA: Elmira Amooei**\n",
        "\n",
        "**Questions?: Rather than email, please ask any questions through the Discussion Board on Brightspace. That way, everyone can benefit from the answer**\n",
        "\n",
        "** Deadline: See Brightspace end date**\n",
        "\n",
        "---\n",
        "\n",
        "### The goal is to develop an emotion detection CNN-based model that can detect emotions from images in real-time.\n",
        "\n",
        "#### Instructions:\n",
        "> **DO NOT** wait to the last minute to complete this assignment as it can take up to 10 hours to do this assignment if you are unfmiliar with Python and Machine Learning libraries. Your full notebook should not take more than 100 minutes to run on *T4 GPU*. (My full notebook takes under 35 minutes to run on T4 GPU on colab)\n",
        "\n",
        ">  Step-by-step instructions are given in the notebook. Make sure to follow them all. Your solutions must be self-contained in this notebook; no other supplementary material or files will be accepted. As soon as I open your assignment's notebook , I will click \"runtime\" â†’ \"run all\". Ensure your notebook works properly without any errors and your results are clearly displayed, as instructed.\n",
        "\n",
        "> For text answers, like explanations, make sure to put your answers in the *Markdown* cells below that have this emoji (âœ…). Just double-click on the emoji and you can start typing. The questions that you must answer are placed in markdown cells with this emoji (â“) .\n",
        "\n",
        "> Feel free to add code blocks if you wish. However, make sure to have sufficient comments in your code to describe what the code is doing. *( You don't need to add a comment to each line, just make sure it is clear what your functions are doing.)*\n",
        "\n",
        "> The functions you need are already imported for you in the appropriate sections. You can reorganize the imports or import full packages (instead of specific functions) if you prefer to do so. *Make sure you are not removing the libraries by mistake as it will raise errors when I run your notebook and you will lose mark.*\n",
        "\n",
        "> The required dataset is uploaded on Brightspace. Download it and store it in your Google Drive. It should be under your \"My Drive\" (After uploading it to your Google Drive, check the location by right clicking on the file *-> File Information -> Details -> Location*).  **Do not** put it into any sub-folder as  I won't be able to run your code on my data. It will raise an error and you will lose marks.\n",
        "\n",
        "> I suggest doing your coding and first making sure everything works fine on a CPU. Then do the actual model training on a GPU. To chage your runtime from CPU to GPU and vice versa, select **Runtime** -> **Change Runtime Type** -> under **Hardware accelerator** clock on CPU or T4 GPU.\n",
        "\n",
        "> Submit your Notebook as a *.ipynb* file that adopts this naming convention: ***SYSC4415W24_A2_FIRSTNAME_LASTNAME_StudentID.ipynb*** on *Brightspace*. No other submission (e.g., through email) will be accepted.\n"
      ],
      "metadata": {
        "id": "1fuDLhABGWYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0) Context\n",
        "\n",
        "Meet Dr. Emily Hayes(ðŸ‘©ðŸ»â€âš•ï¸), a leading psychologist who specializes in treating patients with various emotional disorders. Despite her expertise, Dr. Hayes often finds it challenging to accurately assess her patients' emotions during therapy sessions. Traditional methods, such as self-reporting and facial expressions, can be unreliable and subjective.\n",
        "\n",
        "Determined to find a more effective solution, Dr. Hayes hears of James Green who works with a team of data scientists and engineers that can develop an emotion recognition model based on the Facial Expression Recognition 2013 (FER-2013) image dataset. This dataset contains thousands of facial images labeled with six basic emotions: happiness, sadness, anger, surprise, disgust, and fear (plus 'neutral').\n",
        "\n",
        "Together, they embark on a journey to create a convolutional neural network (CNN) capable of accurately identifying and interpreting subtle facial cues. Their goal is to build a tool that can assist therapists like Dr. Hayes in better understanding their patients' emotions and providing more targeted interventions."
      ],
      "metadata": {
        "id": "-YdH-JDyLw9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Initializations\n"
      ],
      "metadata": {
        "id": "VgiZpuZnL6Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to mount Google Drive\n",
        "\n",
        "*Note that it will open a new window to get authorizations to use your Google Drive. Just follow the steps.*"
      ],
      "metadata": {
        "id": "atHKfMgPvU0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TkFDP34vTau",
        "outputId": "c5d61de3-d0d9-421f-a037-2d93e74e339f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the data into a folder called FER-2013.\n",
        "\n",
        "> This will take a few moments.\n",
        "\n",
        "> This will not take any space on your Google Drive. ðŸ¤—"
      ],
      "metadata": {
        "id": "iE6IZ5xBz2r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the data (be sure not to rename the data file you downloaded from Brightspace)\n",
        "!unrar x /content/drive/MyDrive/FER-2013.rar\n"
      ],
      "metadata": {
        "id": "o0DMFRnoym2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "5q5PkmlY0qLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 7 categories to your dataset as you can see below:"
      ],
      "metadata": {
        "id": "Egx8F3xG27Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/FER-2013\"\n",
        "categories = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
        "data = []"
      ],
      "metadata": {
        "id": "l49fm2ka0_wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use \"data_path\" and \"categories\" above to  loop over the image paths and poplate a pandas dataframe with data and the corresponding emotion from each file. Print out the dimensions of your entire dataframe using `print()`."
      ],
      "metadata": {
        "id": "oCdyvmLp1o4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put data into dataframe\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "U9IDwxSQ1DvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use the `head` method to print out the first 7 rows.\n",
        "\n"
      ],
      "metadata": {
        "id": "rNouQbUE45UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top 3 rows\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "u6MfR4AR5Dpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "WYRqIXoT8_Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Use the library above to look at one image from each of the categories.\n",
        "\n",
        "*Please, do NOT apply any transformation to the images.*"
      ],
      "metadata": {
        "id": "zDEERNh39J6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show one image of each of the categories\n",
        "\n",
        "# YOUR CODE GOES HERE\n",
        "\n"
      ],
      "metadata": {
        "id": "o041AfTG5iuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Preprocessing"
      ],
      "metadata": {
        "id": "HXvrJax-Kehf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start off by doing some preproccessing:\n",
        "\n",
        "1. Make sure your images are all 48*48. Use assert() and resize() if needed.\n",
        "2. Covert your images to grayscale.\n",
        "3. Using **Pytorch**, create a dataloader and split your dataset into 80% train and 20% test.\n",
        "4. Create two bar charts showing the distribution of each of the 7 class labels in both your training and testing subsets.\n",
        "\n",
        " *Note that the methods you need are already imported.*"
      ],
      "metadata": {
        "id": "UJT2ZDvQ-acS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â“\n",
        "\n",
        "1. Do we need to use one-hot encoding? Why or why not?\n",
        "2. How will the grayscale transformation help our training?"
      ],
      "metadata": {
        "id": "xnc78S_Nu0t5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…  \n",
        "1.\n",
        "\n",
        "\n",
        "2."
      ],
      "metadata": {
        "id": "eZ-yhT8PvT-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "8ZT98G1s-wAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations and split the dataset into train and test\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "7UIQsNXI5ybj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two bar charts showing the distribution across the 7 class labels for your training and testing subsets.\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "V0zZzQ5RGNds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Baseline model"
      ],
      "metadata": {
        "id": "QiAS4v-8Afwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a baseline CNN model. You will improve on this model later on...\n",
        "\n",
        "Your  CNN should:\n",
        "1. Have two convolutional layers,\n",
        "2. Use a Padding = 1,\n",
        "3. Have a Kernel size = 3,\n",
        "4. Have one max pooling layer.\n",
        "\n",
        "\n",
        "*Note that the libararies you will need are already imported here.*"
      ],
      "metadata": {
        "id": "RfjDpS61AlzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchsummary"
      ],
      "metadata": {
        "id": "62JkFAlJDChA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import possible choices\n",
        "from sklearn.metrics import  accuracy_score\n",
        "from sklearn.metrics import  precision_score\n",
        "from sklearn.metrics import  recall_score\n",
        "from sklearn.metrics import  f1_score\n",
        "from sklearn.metrics import  classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import  roc_auc_score"
      ],
      "metadata": {
        "id": "wbZ4KPghE7uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your baseline CNN\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "iNlm5e0pDLmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â“\n",
        "\n",
        "List 3 ideas for how you will improve your baseline model (e.g., change the padding, kernel, etc.) For each idea, explain why you believe the idea may improve your model.\n",
        "\n",
        "*Below, you apply your ideas to the CNN you will build in later steps and report how they made your results better/worse.*"
      ],
      "metadata": {
        "id": "iYitS0vi_FCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…\n"
      ],
      "metadata": {
        "id": "Tpo3dn1A_QQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Lets train our baseline model!"
      ],
      "metadata": {
        "id": "l-OmFzigEeVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Train your baseline CNN below for 10 epochs.\n",
        "2. Print the loss for each epoch.\n",
        "3. Evaluate your model on the test data.\n"
      ],
      "metadata": {
        "id": "UYHdUYvmD8rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â“\n",
        "\n",
        "Choose one performance metric to report your results. Explain why you chose this metric. (e.g. accuarcy, recall, etc.)"
      ],
      "metadata": {
        "id": "gIH2CaHUyi4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…"
      ],
      "metadata": {
        "id": "-XRKNLi7yigD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your model\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "D5f4pqr19Dx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test using your choosen metric\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "mQ7fvFaO9DvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your model, loss function, and optimizer\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "wAf3yMrFAjcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â“\n",
        "\n",
        "Plot the confusion matrix for your results. Explain to Dr. Hayes what this confusion matrix is showing and how she can interpret it. Also, explain how your chosen performance metric relates to the confusion table *(in plain language, not an equation)*.\n",
        "\n",
        "* *Note that the libraries you need are imported below.*"
      ],
      "metadata": {
        "id": "qW2l7RrJE91G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…"
      ],
      "metadata": {
        "id": "QQ0-THpnzQhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "sZhtWVusFaim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and plot the confusion matrix\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "Yoa_s3rABXOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) The real deal!\n",
        "\n",
        "Lets improve your CNN to improve your baseline model!\n",
        "\n",
        "Try to obtain a model that has the **best performance** (based on the metric you decided is best).\n",
        "\n",
        "Make sure to include your 3 ideas on how to improve your baseline model (that you mentioned in a question box a few cells ago.)\n",
        "\n",
        "* Make sure that your code shows how you explored different ideas.\n",
        "* Each of the three attempts below should show the addition of one new idea in your model.\n",
        "* Include performance evaluation using your selected performance metric and a confusion matrix.\n",
        "* Be sure to add comments in the code blocks to show how you modified the model architecture."
      ],
      "metadata": {
        "id": "FwcqrOPoFvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5a) Your first (ðŸ¥‡) attempt at improving your model goes here. ðŸ‘‡ðŸ»"
      ],
      "metadata": {
        "id": "2fRpgFam0eFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your improved CNN model, call it ImprovedCNNOne()\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "MWwrVCRZE5wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test set\n",
        "\n",
        "# YOUR CODE GOES HERE\n",
        "\n"
      ],
      "metadata": {
        "id": "a6PgLrgZAR8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model and create the confusion matrix\n",
        "\n",
        "# YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "8JFUfwTEILC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5b) Your second (ðŸ¥ˆ) **attempt** at improving your model goes here. ðŸ‘‡ðŸ»"
      ],
      "metadata": {
        "id": "-YvTdy7nlRfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your finetuned CNN model, call it ImprovedCNNTwo()\n",
        "\n",
        "# YOUR CODE GOES HERE"
      ],
      "metadata": {
        "id": "y0eFOtT7lTHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test set\n",
        "\n",
        "# YOUR CODE GOES HERE"
      ],
      "metadata": {
        "id": "2t8c-IhalTEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model and create the confusion matrix\n",
        "\n",
        "# YOUR CODE GOES HERE"
      ],
      "metadata": {
        "id": "cwioBOknlTBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5c) Your third (ðŸ¥‰) attempt at improving your model goes here. ðŸ‘‡ðŸ»"
      ],
      "metadata": {
        "id": "Q484k_YqlRTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your finetuned CNN model, call it ImprovedCNNThree()\n",
        "\n",
        "# YOUR CODE GOES HERE"
      ],
      "metadata": {
        "id": "tHFXUtsqlT0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test set\n",
        "\n",
        "# YOUR CODE GOES HERE"
      ],
      "metadata": {
        "id": "cRFp_2EolTx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model and create the confusion matrix\n",
        "\n",
        "# YOUR CODE GOES HERE"
      ],
      "metadata": {
        "id": "ZzSXxUGxlTvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â“\n",
        "\n",
        "Decide which model you would like to present to Dr. Hayes as your final product. Using your performance metric, explain to her why you think this model is the best one. (Make sure to include your confusion matrix and your performance measure.)"
      ],
      "metadata": {
        "id": "VGXEgtQGlRLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…"
      ],
      "metadata": {
        "id": "huNVQcXrmFzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Final thoughts"
      ],
      "metadata": {
        "id": "k0KvHMvKOiKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â“\n",
        "\n",
        "Questions from Dr. Hayes:\n",
        "\n",
        "1. Now that you have developed this model, briefly explain how you will continue to improve your model in future versions?\n",
        "\n",
        "2. A competitor has recently trained an FFNN on the same dataset that performs worse than your model. Why do you think your CNN performs better?\n"
      ],
      "metadata": {
        "id": "mRLIbFTTMkLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6VqbS_7QNVP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 7) An opportunity! *(optional)*\n",
        "\n",
        "An external investor is ready to run your model on small device that has a webcam. The device has limited compute resources because it needs to be kept cheap and accessible.\n",
        "\n",
        "* **Optional step**\n",
        "> Run the code bellow to see if your model can perform in realtime.\n",
        "\n",
        "*Please DO NOT change the code below.*"
      ],
      "metadata": {
        "id": "pqUiELiD-3FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neccessary libraries\n",
        "import cv2\n",
        "from IPython.display import display, Image, Javascript\n",
        "from PIL import Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ],
      "metadata": {
        "id": "NFIl2UAM_oJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "6NoCDPP5wTFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All done! ðŸ¤©"
      ],
      "metadata": {
        "id": "kNvUpMBtOmwk"
      }
    }
  ]
}